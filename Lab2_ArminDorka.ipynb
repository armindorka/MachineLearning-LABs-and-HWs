{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb7Nui77r_v"
      },
      "source": [
        "# Lab 2. PyTorch models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nCbV6ST2fpL"
      },
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.* [*Instructions for passing*]\n",
        "\n",
        " - For each task:\n",
        "   - **Complete the code** where indicated.\n",
        "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIH0AWH2_jxD"
      },
      "source": [
        "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
        "\n",
        "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gQUsFpCD0aP"
      },
      "source": [
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXx3rp8D2Nm"
      },
      "source": [
        "\n",
        "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
        "\n",
        "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ChFhB0bauM"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiDj5c8beHt"
      },
      "source": [
        "- Import PyTorch and load a sample dataset\n",
        "- Sequential fully connected network\n",
        "- Other useful functions (Saving/Loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXwomm0bxug"
      },
      "source": [
        "### Section 1: Import PyTorch and load a sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9hfGXIA6Ek"
      },
      "source": [
        "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzUBH9xhn0JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7mgvEN8mtN6"
      },
      "outputs": [],
      "source": [
        "import torch as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8zL6JdKIasB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Ek6pMT_pdg_",
        "outputId": "fb069ba7-a96a-45cb-c1c6-cf35ba028ee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# version?\n",
        "pt.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhFeXn8MgFT2"
      },
      "source": [
        "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfKi-cJn0JP",
        "outputId": "5e78d350-9f9a-466b-ed07-f5141a5b5458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 762, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 762 (delta 0), reused 2 (delta 0), pack-reused 758 (from 1)\u001b[K\n",
            "Receiving objects: 100% (762/762), 105.85 MiB | 32.33 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zalandoresearch/fashion-mnist data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efgvJL-WwWu"
      },
      "source": [
        "#### Dataset handling: Traditional way with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lga5zwx6BJti"
      },
      "source": [
        "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
        "\n",
        "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SSWdpC1tjnL"
      },
      "source": [
        "Lets check out the `mnist_reader` they mention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYgIPJnr4Cz",
        "outputId": "acaded76-414e-4e4e-c6fe-b6a95e336c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def load_mnist(path, kind='train'):\n",
            "    import os\n",
            "    import gzip\n",
            "    import numpy as np\n",
            "\n",
            "    \"\"\"Load MNIST data from `path`\"\"\"\n",
            "    labels_path = os.path.join(path,\n",
            "                               '%s-labels-idx1-ubyte.gz'\n",
            "                               % kind)\n",
            "    images_path = os.path.join(path,\n",
            "                               '%s-images-idx3-ubyte.gz'\n",
            "                               % kind)\n",
            "\n",
            "    with gzip.open(labels_path, 'rb') as lbpath:\n",
            "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
            "                               offset=8)\n",
            "\n",
            "    with gzip.open(images_path, 'rb') as imgpath:\n",
            "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
            "                               offset=16).reshape(len(labels), 784)\n",
            "\n",
            "    return images, labels\n"
          ]
        }
      ],
      "source": [
        "!cat data/utils/mnist_reader.py # linux / mac\n",
        "#!type data\\utils\\mnist_reader.py # windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-Nz93XtsRy"
      },
      "source": [
        "What values does the parameter `kind` take?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXvbQYytQfW",
        "outputId": "65db1000-8b92-4507-ec94-4a72b58fa748"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t10k-images-idx3-ubyte.gz',\n",
              " 'train-images-idx3-ubyte.gz',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 'train-labels-idx1-ubyte.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('data/data/fashion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsK-umdt4pc"
      },
      "source": [
        "Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_i0BcD_qwx0"
      },
      "outputs": [],
      "source": [
        "# import mnist_reader:\n",
        "import data.utils.mnist_reader as mnist_reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2DoMiOnplgm"
      },
      "outputs": [],
      "source": [
        "# load data:\n",
        "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KfXaFeBQLY"
      },
      "source": [
        "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQGzWUZABSdD",
        "outputId": "8d36f20c-37b8-40b1-ca2e-9b76adf4f9b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# type?\n",
        "type(X_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA4f__FUppwQ",
        "outputId": "26879273-1a41-483e-e3df-3ffc497e498e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# shape?\n",
        "X_train_full.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRWMKbUZnJJ",
        "outputId": "97abbff6-e2b7-4101-8de9-947abaf2b7be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "np.unique(y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSk4-jABU95"
      },
      "source": [
        "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNJONOHptj6",
        "outputId": "74a4a4cf-539c-4f6b-ac0f-58a1ecd8ec7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# dtype?\n",
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZE6WfngbYs"
      },
      "source": [
        "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
        "\n",
        "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUEmqGNGoZ_W"
      },
      "source": [
        "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb6n6PzLgjRj"
      },
      "outputs": [],
      "source": [
        "# Introduced in the coursebook\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azOEHFspR7u5"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtvJAWxvhEP"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
        "  - Use `X_train_full` and `y_train_full`\n",
        "  - Enable `shuffle` and `stratification`\n",
        "\n",
        "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQuXXouFLDRN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# normalize:\n",
        "X_train_full = X_train_full / 255.\n",
        "\n",
        "# split data: (continued)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full,\n",
        "    y_train_full,\n",
        "    test_size=0.5,\n",
        "    shuffle=True,\n",
        "    stratify=y_train_full,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4gVzDXcR7u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5179daaf-b70b-423d-9e19-ad444e55e901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (30000, 784)\n",
            "y_train shape: (30000,)\n",
            "X_valid shape: (30000, 784)\n",
            "y_valid shape: (30000,)\n"
          ]
        }
      ],
      "source": [
        "# shape?\n",
        "#continue\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_f0SkwQR7u7"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTSsrnEF2XC"
      },
      "source": [
        "Here we prepared the class names of the fashion MNIST dataset for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRc7tKoIsFx4"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eBOMMsxAxrfj",
        "outputId": "74df3922-f2d7-46cf-e8fe-33101ecdb2a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Use the numeric label to get the class name, e.g:\n",
        "class_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch49P29iEDxC"
      },
      "source": [
        "We can also try to see each data instance by using **plt.imshow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FSwEtbA6KmFg",
        "outputId": "f93168ae-ebb7-4d82-b19d-3e5e34957b82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = np.random.randint(0, X_train.shape[0])\n",
        "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
        "plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPR-OZKyStX"
      },
      "source": [
        "#### Optimizing memory consuption using pipelines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w2ohRDo2eW"
      },
      "source": [
        "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
        "\n",
        "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
        "\n",
        "---\n",
        "***An abstract class representing a Dataset.***\n",
        "\n",
        "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcvyxGDerVFS"
      },
      "outputs": [],
      "source": [
        "from numpy.typing import NDArray\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
        "    # normalize:\n",
        "    self.X = X.astype(np.float32) / 255.0\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "    # load data:\n",
        "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "    # split data:\n",
        "    n = len(labels)\n",
        "    n_train = int(n * fraction_train)\n",
        "    n_validation = int(n * fraction_validation)\n",
        "\n",
        "    data_train = FashionMNIST(\n",
        "        data[:n_train],\n",
        "        labels[:n_train]\n",
        "    )\n",
        "    data_valid = FashionMNIST(\n",
        "        data[n_train:n_train+n_validation],\n",
        "        labels[n_train:n_train+n_validation]\n",
        "    )\n",
        "    data_test = FashionMNIST(\n",
        "        data[n_train+n_validation:],\n",
        "        labels[n_train+n_validation:]\n",
        "    )\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0v0JjVOk57s"
      },
      "source": [
        "It works like a list of tuples `(X, y)` in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCOTVO81lZyD"
      },
      "outputs": [],
      "source": [
        "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjOC4aIlpfp",
        "outputId": "63fd8d70-77c8-4e4b-8f51-fcd4a2c9d3e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49000"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# call to __len__:\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFLbrYUlrdL",
        "outputId": "2d51fdea-d168-4883-9166-310736245fe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
              "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
              "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
              "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
              "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
              "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
              "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
              "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
              "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
              "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
              "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
              "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
              "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
              "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
              "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
              "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
              "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
              "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
              "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
              "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
              "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
              "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
              "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
              "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
              "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
              "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
              "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
              "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
              "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
              "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
              "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
              "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
              "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
              "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
              "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
              "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
              "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
              "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
              "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
              "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
              "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
              "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
              "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
              "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
              "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
              "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
              "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
              "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
              "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
              "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
              "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
              "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
              "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
              "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
              "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
              "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
              "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
              "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
              "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
              "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
              "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
              "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
              "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
              "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
              "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
              "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
              "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
              "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
              "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
              "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
              "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
              "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
              "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
              "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
              "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
              "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
              "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
              "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
              "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
              "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
              "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
              "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
              "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
              "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
              "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
              "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
              "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
              "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
              "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
              "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
              "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
              "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
              "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
              "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
              "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
              "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
              "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
              " np.uint8(2))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# call to __getitem__:\n",
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1u-U7X-fXCB"
      },
      "source": [
        "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EADlbbqB01Kw"
      },
      "outputs": [],
      "source": [
        "# unzip data:\n",
        "target_dir = 'data/data/fashion/unzipped'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "for i, x in enumerate(data):\n",
        "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
        "  with open(file, 'wb') as f:\n",
        "    np.save(f, x.reshape((28, 28)))\n",
        "\n",
        "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
        "  np.save(f, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0YptsZ-QaG",
        "outputId": "e8f165f1-70be-499c-912d-d664823765cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_67431.npy',\n",
              " 'img_4951.npy',\n",
              " 'img_1250.npy',\n",
              " 'img_41482.npy',\n",
              " 'img_8223.npy',\n",
              " 'img_6140.npy',\n",
              " 'img_35312.npy',\n",
              " 'img_55257.npy',\n",
              " 'img_56894.npy',\n",
              " 'img_19954.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "os.listdir(target_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICJqXvjc1Y"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following class.\n",
        "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
        "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
        "- Use the variable `target_dir` as the path to the unzipped data.\n",
        "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmiKviaXkHYb"
      },
      "outputs": [],
      "source": [
        "target_dir = 'data/data/fashion/unzipped'\n",
        "\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, indices:NDArray[np.int32], labels:NDArray[np.int8]) -> None:\n",
        "    self.indices = indices\n",
        "    self.labels  = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx:int) ->  Tuple[np.ndarray, int]:\n",
        "    # complete\n",
        "    actual_idx = self.indices[idx]\n",
        "    label = self.labels[idx]\n",
        "\n",
        "    img_path = os.path.join(target_dir, f'img_{actual_idx}.npy')\n",
        "    image = np.load(img_path).astype(np.float32) / 255.0  # Normalize\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float, stratify:bool=True, shuffle:bool=False) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "    # complete\n",
        "    # Load labels\n",
        "    labels_path = os.path.join(target_dir, 'labels.npy')\n",
        "    all_labels = np.load(labels_path)\n",
        "\n",
        "    # Create indices array\n",
        "    indices = np.arange(len(all_labels), dtype=np.int32)\n",
        "\n",
        "    # split into train_valid and test\n",
        "    test_size = fraction_test\n",
        "    stratify_labels = all_labels if stratify else None\n",
        "\n",
        "    idx_train_valid, idx_test, y_train_valid, y_test = train_test_split(\n",
        "        indices,\n",
        "        all_labels,\n",
        "        test_size=test_size,\n",
        "        stratify=stratify_labels,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    # split train_valid into train and valid\n",
        "    valid_size = fraction_validation / (1.0 - fraction_test)\n",
        "    stratify_labels = y_train_valid if stratify else None\n",
        "\n",
        "    idx_train, idx_valid, y_train, y_valid = train_test_split(\n",
        "        idx_train_valid,\n",
        "        y_train_valid,\n",
        "        test_size=valid_size,\n",
        "        stratify=stratify_labels,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    # datasets\n",
        "    data_train = FashionMNIST(idx_train, y_train)\n",
        "    data_valid = FashionMNIST(idx_valid, y_valid)\n",
        "    data_test = FashionMNIST(idx_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxU6CLfR7vD"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzLUn4kGGVU"
      },
      "source": [
        "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ox0oodObDPH"
      },
      "source": [
        "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYJGAsARQxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZmqQ9W2pp5b"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2dJNcKrESEU"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(data_train,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                                                  # If specified, shuffle must not be specified.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "                                                  # If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj964nU9EVbq"
      },
      "outputs": [],
      "source": [
        "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_valid = DataLoader(data_valid,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu56t0MPO1PF"
      },
      "outputs": [],
      "source": [
        "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz-SbwJxZ1t"
      },
      "source": [
        "### Section 2: Sequential fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fh7PjMWqOnS"
      },
      "source": [
        "#### Instantiating the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuxZ7HZgpwm"
      },
      "source": [
        "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
        "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
        "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
        "\n",
        "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpDMjCbExvzN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
        "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        x = F.relu(self.layer1(x))\n",
        "        return F.softmax(self.layer2(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvjomL9CJcrr"
      },
      "source": [
        "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iLn73SNJenS",
        "outputId": "4c74da6c-1c01-47f8-f6fa-604fb87757ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CustomNetwork()\n",
        "summary(model, input_size=(784,), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_iVtGfSEe7b"
      },
      "source": [
        "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOcLYKLEpgw"
      },
      "source": [
        "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5iYpVqcwYL9",
        "outputId": "bcaf2d6f-d12c-4279-bbe1-ddfe9792dd2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=100, bias=True),\n",
              " Linear(in_features=100, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwCNTJ4nGyW",
        "outputId": "afacc86c-2a15-41fe-af04-c2d1a2984ab9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "list(model.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJcb7xZtpEAZ",
        "outputId": "750abd63-c89d-4712-db0b-1707dd52e45b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=100, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.get_submodule('layer1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnS08_Lom1s",
        "outputId": "a7aaf81e-2312-4e40-b467-0ca2fa4f5469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  CustomNetwork(\n",
              "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
              "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )),\n",
              " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# All modules in the model (including itself):\n",
        "list(model.named_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAa1OQuPnlNF",
        "outputId": "fa70c5e7-0163-4aac-bd39-3e0a8fc22b12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0195, -0.0253,  0.0290,  ...,  0.0003, -0.0183,  0.0169],\n",
              "         [-0.0309,  0.0297, -0.0343,  ..., -0.0147,  0.0010, -0.0257],\n",
              "         [-0.0309, -0.0102,  0.0234,  ..., -0.0356,  0.0214,  0.0254],\n",
              "         ...,\n",
              "         [-0.0070, -0.0143,  0.0170,  ..., -0.0002,  0.0013, -0.0072],\n",
              "         [ 0.0213, -0.0002, -0.0113,  ..., -0.0067,  0.0205,  0.0054],\n",
              "         [-0.0089, -0.0242, -0.0027,  ...,  0.0168,  0.0058, -0.0103]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0160, -0.0269,  0.0236,  0.0279,  0.0039,  0.0027, -0.0133,  0.0040,\n",
              "         -0.0109, -0.0221, -0.0144,  0.0094, -0.0116,  0.0144,  0.0294, -0.0098,\n",
              "         -0.0251, -0.0240, -0.0179, -0.0352,  0.0077, -0.0278, -0.0060,  0.0306,\n",
              "         -0.0038, -0.0145, -0.0345,  0.0294, -0.0057, -0.0026, -0.0338,  0.0228,\n",
              "          0.0277, -0.0216,  0.0194,  0.0191, -0.0271,  0.0071, -0.0273, -0.0168,\n",
              "         -0.0294, -0.0031,  0.0202, -0.0162,  0.0070,  0.0222,  0.0294,  0.0199,\n",
              "          0.0058,  0.0224,  0.0304, -0.0256, -0.0229,  0.0245,  0.0118,  0.0327,\n",
              "          0.0297, -0.0304,  0.0227,  0.0008,  0.0281,  0.0105,  0.0229,  0.0352,\n",
              "          0.0263,  0.0157,  0.0127, -0.0240, -0.0333,  0.0100, -0.0303,  0.0154,\n",
              "         -0.0313,  0.0075, -0.0188,  0.0068, -0.0194,  0.0064, -0.0151,  0.0054,\n",
              "         -0.0188, -0.0056,  0.0289, -0.0266,  0.0219,  0.0126,  0.0177, -0.0260,\n",
              "         -0.0113,  0.0290,  0.0121, -0.0140,  0.0223, -0.0064, -0.0266,  0.0206,\n",
              "          0.0117,  0.0040,  0.0098, -0.0291], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW334iaoA7z",
        "outputId": "24621eec-de64-418f-c88b-68628df31016"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.0195, -0.0253,  0.0290,  ...,  0.0003, -0.0183,  0.0169],\n",
              "          [-0.0309,  0.0297, -0.0343,  ..., -0.0147,  0.0010, -0.0257],\n",
              "          [-0.0309, -0.0102,  0.0234,  ..., -0.0356,  0.0214,  0.0254],\n",
              "          ...,\n",
              "          [-0.0070, -0.0143,  0.0170,  ..., -0.0002,  0.0013, -0.0072],\n",
              "          [ 0.0213, -0.0002, -0.0113,  ..., -0.0067,  0.0205,  0.0054],\n",
              "          [-0.0089, -0.0242, -0.0027,  ...,  0.0168,  0.0058, -0.0103]],\n",
              "         requires_grad=True)),\n",
              " ('layer1.bias',\n",
              "  Parameter containing:\n",
              "  tensor([ 0.0160, -0.0269,  0.0236,  0.0279,  0.0039,  0.0027, -0.0133,  0.0040,\n",
              "          -0.0109, -0.0221, -0.0144,  0.0094, -0.0116,  0.0144,  0.0294, -0.0098,\n",
              "          -0.0251, -0.0240, -0.0179, -0.0352,  0.0077, -0.0278, -0.0060,  0.0306,\n",
              "          -0.0038, -0.0145, -0.0345,  0.0294, -0.0057, -0.0026, -0.0338,  0.0228,\n",
              "           0.0277, -0.0216,  0.0194,  0.0191, -0.0271,  0.0071, -0.0273, -0.0168,\n",
              "          -0.0294, -0.0031,  0.0202, -0.0162,  0.0070,  0.0222,  0.0294,  0.0199,\n",
              "           0.0058,  0.0224,  0.0304, -0.0256, -0.0229,  0.0245,  0.0118,  0.0327,\n",
              "           0.0297, -0.0304,  0.0227,  0.0008,  0.0281,  0.0105,  0.0229,  0.0352,\n",
              "           0.0263,  0.0157,  0.0127, -0.0240, -0.0333,  0.0100, -0.0303,  0.0154,\n",
              "          -0.0313,  0.0075, -0.0188,  0.0068, -0.0194,  0.0064, -0.0151,  0.0054,\n",
              "          -0.0188, -0.0056,  0.0289, -0.0266,  0.0219,  0.0126,  0.0177, -0.0260,\n",
              "          -0.0113,  0.0290,  0.0121, -0.0140,  0.0223, -0.0064, -0.0266,  0.0206,\n",
              "           0.0117,  0.0040,  0.0098, -0.0291], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "list(model.named_parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjmrnDXobxo",
        "outputId": "c85684de-7217-440a-b28c-fd288294c144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0195, -0.0253,  0.0290,  ...,  0.0003, -0.0183,  0.0169],\n",
              "        [-0.0309,  0.0297, -0.0343,  ..., -0.0147,  0.0010, -0.0257],\n",
              "        [-0.0309, -0.0102,  0.0234,  ..., -0.0356,  0.0214,  0.0254],\n",
              "        ...,\n",
              "        [-0.0070, -0.0143,  0.0170,  ..., -0.0002,  0.0013, -0.0072],\n",
              "        [ 0.0213, -0.0002, -0.0113,  ..., -0.0067,  0.0205,  0.0054],\n",
              "        [-0.0089, -0.0242, -0.0027,  ...,  0.0168,  0.0058, -0.0103]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.get_parameter('layer1.weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cXyZlQwJca"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
        "\n",
        "---\n",
        "\n",
        "The above network is very simple. Implement a better version with the following layers:\n",
        "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear hidden layer** of size 200, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear output layer**, with a **softmax** activation function.\n",
        "\n",
        "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`.\n",
        "Make sure the network has the following layers (i.e. use `torch.nn.Dropout` instead of `torch.nn.functional.dropout`):\n",
        "\n",
        "    --------------------------\n",
        "            Layer (type)      \n",
        "    ==========================\n",
        "             Linear-1         \n",
        "            Dropout-2         \n",
        "             Linear-3         \n",
        "            Dropout-4         \n",
        "             Linear-5         \n",
        "    ==========================\n",
        "    Total params: 297,710     \n",
        "    Trainable params: 297,710\n",
        "    Non-trainable params: 0   \n",
        "    --------------------------\n",
        "\n",
        "See [here](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for documentation of the `torch.nn.Dropout` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpYsDHgzwuwI"
      },
      "outputs": [],
      "source": [
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self, dropout:float=.2) -> None:\n",
        "        super().__init__()\n",
        "        #continue\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=300, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layer2 = nn.Linear(in_features=300, out_features=200, bias=True)\n",
        "        self.dropout2 = nn.Dropout(p=dropout)\n",
        "        self.layer3 = nn.Linear(in_features=200, out_features=10, bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        #continue\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.layer3(x))\n",
        "\n",
        "        return F.softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yN435-5R7vM"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLMuUG172fpl"
      },
      "source": [
        "**Alternative but more restrictive:** `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mUUHh3V2fpl"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Sequential\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7WydIqz2fpl"
      },
      "source": [
        "Unnamed layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJjFULGW2fpm"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PFHTr2X2fpm"
      },
      "source": [
        "Named layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG5_cdf12fpm"
      },
      "outputs": [],
      "source": [
        "model = Sequential(OrderedDict([\n",
        "    ('layer1',      nn.Linear(in_features=784, out_features=100, bias=True)),\n",
        "    ('activation1', nn.ReLU()),\n",
        "    ('layer1',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
        "    ('activation2', nn.Softmax(dim=-1))\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo7nYEYp-Wb"
      },
      "source": [
        "### Section 3: Training the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Q14ZHssu1E"
      },
      "source": [
        "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
        "- `cpu`: any of your computer's CPUs\n",
        "- `cpu:0`:the first of your computer's CPUs\n",
        "- `cuda`: any of your computer's GPUs\n",
        "- `cuda:2`: the third GPU of you computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HxsXGisi9T",
        "outputId": "cc28b0ae-1e80-4b29-cdbe-1f064a104947"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# get gpu if available else cpu:\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs-4FS3uKsMZ"
      },
      "outputs": [],
      "source": [
        "# move a model or tensor to the device:\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZAZKxtFBFR"
      },
      "source": [
        "Prediction on new instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "SdDh74y0i7fX",
        "outputId": "24281917-b7f0-42c4-aea7-d0a94d8e97f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x784 and 100x10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-88d3adfbd58b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this returns a probability?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x784 and 100x10)"
          ]
        }
      ],
      "source": [
        "X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
        "y_proba = model(X_new) # this returns a probability?\n",
        "y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "nU8cAN3fi99y",
        "outputId": "52278ae0-84a1-406c-9c48-d0402c7e4889"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_proba' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-0f0bed5e4aad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#if we want to know the class names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_proba' is not defined"
          ]
        }
      ],
      "source": [
        "np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wLOuG8vK_r"
      },
      "source": [
        "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
        "\n",
        "This is necessary, as for example dropout layers are inactive during prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRxMYLRqnoU"
      },
      "source": [
        "In order to train the network, we need to define a training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqjxNg_mDP2z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBxz4ZXkz4hT"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adSjw6i50L3b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SASZ5PCXq4tr"
      },
      "outputs": [],
      "source": [
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
        "  # instantiate optimizer:\n",
        "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train for one epoch:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # save metrics:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    # print message:\n",
        "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08uZrmWMCmq"
      },
      "source": [
        "Fit the model for 30 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "U1VqXewrMCVQ",
        "outputId": "57307744-f77a-42a8-a9e8-16056227a964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\tloss_train = 2.30;\tloss_valid = 2.28;\tf1_valid = 0.10;\n",
            "Epoch 2/30:\tloss_train = 2.23;\tloss_valid = 2.14;\tf1_valid = 0.13;\n",
            "Epoch 3/30:\tloss_train = 2.04;\tloss_valid = 1.96;\tf1_valid = 0.35;\n",
            "Epoch 4/30:\tloss_train = 1.94;\tloss_valid = 1.91;\tf1_valid = 0.44;\n",
            "Epoch 5/30:\tloss_train = 1.90;\tloss_valid = 1.88;\tf1_valid = 0.42;\n",
            "Epoch 6/30:\tloss_train = 1.88;\tloss_valid = 1.86;\tf1_valid = 0.44;\n",
            "Epoch 7/30:\tloss_train = 1.86;\tloss_valid = 1.85;\tf1_valid = 0.44;\n",
            "Epoch 8/30:\tloss_train = 1.85;\tloss_valid = 1.84;\tf1_valid = 0.44;\n",
            "Epoch 9/30:\tloss_train = 1.84;\tloss_valid = 1.83;\tf1_valid = 0.44;\n",
            "Epoch 10/30:\tloss_train = 1.83;\tloss_valid = 1.83;\tf1_valid = 0.44;\n",
            "Epoch 11/30:\tloss_train = 1.83;\tloss_valid = 1.83;\tf1_valid = 0.44;\n",
            "Epoch 12/30:\tloss_train = 1.83;\tloss_valid = 1.82;\tf1_valid = 0.44;\n",
            "Epoch 13/30:\tloss_train = 1.82;\tloss_valid = 1.82;\tf1_valid = 0.44;\n",
            "Epoch 14/30:\tloss_train = 1.82;\tloss_valid = 1.82;\tf1_valid = 0.42;\n",
            "Epoch 15/30:\tloss_train = 1.82;\tloss_valid = 1.82;\tf1_valid = 0.42;\n",
            "Epoch 16/30:\tloss_train = 1.82;\tloss_valid = 1.82;\tf1_valid = 0.42;\n",
            "Epoch 17/30:\tloss_train = 1.82;\tloss_valid = 1.82;\tf1_valid = 0.42;\n",
            "Epoch 18/30:\tloss_train = 1.81;\tloss_valid = 1.82;\tf1_valid = 0.42;\n",
            "Epoch 19/30:\tloss_train = 1.81;\tloss_valid = 1.82;\tf1_valid = 0.42;\n",
            "Epoch 20/30:\tloss_train = 1.81;\tloss_valid = 1.81;\tf1_valid = 0.42;\n",
            "Epoch 21/30:\tloss_train = 1.80;\tloss_valid = 1.77;\tf1_valid = 0.50;\n",
            "Epoch 22/30:\tloss_train = 1.77;\tloss_valid = 1.76;\tf1_valid = 0.50;\n",
            "Epoch 23/30:\tloss_train = 1.76;\tloss_valid = 1.75;\tf1_valid = 0.50;\n",
            "Epoch 24/30:\tloss_train = 1.76;\tloss_valid = 1.75;\tf1_valid = 0.50;\n",
            "Epoch 25/30:\tloss_train = 1.75;\tloss_valid = 1.75;\tf1_valid = 0.50;\n",
            "Epoch 26/30:\tloss_train = 1.75;\tloss_valid = 1.75;\tf1_valid = 0.50;\n",
            "Epoch 27/30:\tloss_train = 1.75;\tloss_valid = 1.75;\tf1_valid = 0.42;\n",
            "Epoch 28/30:\tloss_train = 1.75;\tloss_valid = 1.74;\tf1_valid = 0.50;\n",
            "Epoch 29/30:\tloss_train = 1.75;\tloss_valid = 1.74;\tf1_valid = 0.50;\n",
            "Epoch 30/30:\tloss_train = 1.74;\tloss_valid = 1.74;\tf1_valid = 0.50;\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epoch', ylabel='loss'>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# instantiate model and move to device:\n",
        "model = CustomNetwork().to(device)\n",
        "\n",
        "# train model:\n",
        "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
        "\n",
        "# plot history:\n",
        "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qmHUt5M_nQd"
      },
      "source": [
        "**Evaluation**: `evaluate` will return the metric scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdArSMDi8BI",
        "outputId": "18d52ab3-0877-4be2-8958-1f8dd4c02219"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'f1': 0.6507936507936508}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model, loader_test) #evaluate on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSUB0uJTPBg"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Improve the above training loop with the following steps:\n",
        "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
        "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
        "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
        "\n",
        "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwOaMCDSTOpS"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)\n",
        "\n",
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}\n",
        "\n",
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float, patience:int):\n",
        "  # replace the very basic SGD optimizer with the momentum-based torch.optim.Adam optimizer.\n",
        "  # Compare how the learning curves change after this step. As ADAM is more sensitive to the learning rate, set it to 0.001 after changing the optimizer!\n",
        "  optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  # add a torch.optim.lr_scheduler.LinearLR scheduler (start: 1.0*lr, end:0.33*lr, over 10 epochs).\n",
        "  # Compare how the learning curves change after this step.\n",
        "  scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1., end_factor=.33, total_iters=10)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  # early stopping:\n",
        "  best_state = model.state_dict()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train the first epoc:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # saving the metric results:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1'],\n",
        "      'lr': scheduler.get_last_lr()[-1]\n",
        "    })\n",
        "\n",
        "    # tell the scheduler its a new epoch:\n",
        "    scheduler.step()\n",
        "\n",
        "    # add an early stopping functionality, that stops training when the validation loss has not improved for patience epochs\n",
        "    # and restores the model parameters to the ones achieving the best loss. Use a patience of 5 to retrain the network.\n",
        "    if len(history) > patience:\n",
        "      if all([history[-(patience+1)]['loss_valid'] <= item['loss_valid'] for item in history[-patience:]]):\n",
        "          model.load_state_dict(best_state)\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-hDPkRUY0R"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm2rIvKUP2C"
      },
      "source": [
        "### Section 4: Other useful and frequently used functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4BHXYqUWBH"
      },
      "source": [
        "Save and load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBmnCPTdaAlV"
      },
      "source": [
        "**Option 1:** `torch.save(...)` / `torch.load(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQIhSX16UXpR"
      },
      "outputs": [],
      "source": [
        "pt.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmRkkvbVYqj",
        "outputId": "dd43ea93-c413-4390-f3cc-a53d2aa2076d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  model.pt\n",
            " extracting: model/data.pkl          \n",
            " extracting: model/byteorder         \n",
            " extracting: model/data/0            \n",
            " extracting: model/data/1            \n",
            " extracting: model/data/2            \n",
            " extracting: model/data/3            \n",
            " extracting: model/version           \n",
            " extracting: model/.data/serialization_id  \n"
          ]
        }
      ],
      "source": [
        "# this saves a zipfile!\n",
        "!unzip model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexXOBTKUZH_",
        "outputId": "6cb76ada-270e-46ec-a15f-a3fc0f7a5c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr88yK-8Z5GY"
      },
      "source": [
        "**Option 2:** save/load state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXhrkFhZ9NY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44MB9qujUPys"
      },
      "outputs": [],
      "source": [
        "with open('model_state_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CuVaeSJZgW0",
        "outputId": "e6e1e1d6-0055-4ec0-a53c-2ab7d04af24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with open('model_state_dict.pkl', 'rb') as f:\n",
        "  state_dict = pickle.load(f)\n",
        "model.load_state_dict(state_dict)\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w003CKN5R7vY"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
        "\n",
        "---\n",
        "\n",
        "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
        "\n",
        "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
        "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
        "\n",
        "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qforG1NGbEuq"
      },
      "source": [
        "1. Get training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "YpmUlavla3Py",
        "outputId": "41162ee7-4afd-4be9-906a-6da76d72ab4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d8bf59d8065a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 1.3 check files:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/task5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "# 1.1 you should have received a zip folder \"data.zip\" along with this notebook\n",
        "\n",
        "# 1.2 unzip data.zip\n",
        "!unzip data.zip\n",
        "\n",
        "# 1.3 check files:\n",
        "os.listdir('data/task5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYglS3ybCM8"
      },
      "source": [
        "2. Create Data Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NQ_Rj925R7vY"
      },
      "outputs": [],
      "source": [
        "import torch as pt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# 2.1 Load training data\n",
        "data_train = pd.read_csv('/home/data_train.csv', index_col=0)\n",
        "labels_train = pd.read_csv('/home/labels_train.csv', index_col=0)\n",
        "\n",
        "# 2.2 Load test data (no labels)\n",
        "data_test = pd.read_csv('/home/data_test.csv', index_col=0)\n",
        "\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# scale data\n",
        "scaler = StandardScaler()\n",
        "data_train = scaler.fit_transform(data_train)\n",
        "data_test = scaler.transform(data_test)\n",
        "\n",
        "# torch.tensor after scaled it\n",
        "data_train = pt.tensor(data_train, dtype=pt.float32)\n",
        "labels_train = pt.tensor(labels_train.values, dtype=pt.float32)\n",
        "data_test = pt.tensor(data_test, dtype=pt.float32)\n",
        "\n",
        "# split data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(data_train, labels_train,\n",
        "    test_size=0.3, shuffle=True, random_state=42 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRz2hDYbYJ6"
      },
      "source": [
        "3. Create Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nl0-sMfCR7vZ"
      },
      "outputs": [],
      "source": [
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "\n",
        "loader_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "loader_valid = DataLoader(valid_dataset, batch_size=32)\n",
        "\n",
        "loader_train = DataLoader(train_dataset,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "loader_valid = DataLoader(valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)\n",
        "\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)\n",
        "\n",
        "class RegressionNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(8, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.output = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSyLqesbkYc"
      },
      "source": [
        "4. Train model on `data_train` and `labels_train`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch as pt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def epoch(model: nn.Module, loader_train: DataLoader, optimizer: pt.optim.Optimizer,\n",
        "          loss_fn: Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for X_batch, y_batch in loader_train:\n",
        "        # transfer data to the appropriate device\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # clear previously accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # generate model predictions\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        # compute the loss between predictions and targets\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # perform backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module, loader_valid: DataLoader,\n",
        "             loss_fn: Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]] = None):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    losses = []\n",
        "\n",
        "    with pt.no_grad():\n",
        "        for X_batch, y_batch in loader_valid:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            y_pred = model(X_batch)\n",
        "            predictions.extend(y_pred.cpu().numpy())\n",
        "            labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "            if loss_fn is not None:\n",
        "                loss = loss_fn(y_pred, y_batch)\n",
        "                losses.append(loss.item())\n",
        "\n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "\n",
        "    if loss_fn is None:\n",
        "        return {'mse': mse}\n",
        "    else:\n",
        "        return {'loss': np.mean(losses), 'mse': mse}\n",
        "\n",
        "\n",
        "def fit(model: nn.Module, loader_train: DataLoader, loader_valid: DataLoader,\n",
        "        epochs: int = 10, lr: float = 0.001, patience: int = 5):\n",
        "\n",
        "    optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.33, total_iters=epochs)\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    loss_fn = pt.nn.MSELoss()\n",
        "    history = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "        metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        history.append({\n",
        "            'loss_train': loss_train,\n",
        "            'loss_valid': metrics['loss'],\n",
        "            'mse_valid': metrics['mse']\n",
        "        })\n",
        "\n",
        "        if metrics['loss'] < best_val_loss:\n",
        "            best_val_loss = metrics['loss']\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return pd.DataFrame(history)\n",
        "\n",
        "model = RegressionNetwork().to(device)\n",
        "history = fit(model, loader_train, loader_valid, epochs=100)\n"
      ],
      "metadata": {
        "id": "Ks218n-HI1lS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipIi84zb5ZR"
      },
      "source": [
        "5. Predict `data_test` and save predictions to `submission.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V_gqdJvucm2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8ad4dfc3-e81b-4dbc-8f5c-70606c57015e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5171a4d-ca60-4402-b3cf-4545d340dc73\", \"submission.csv\", 60232)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "with pt.no_grad():\n",
        "      predictions = model(data_test)\n",
        "\n",
        "pd.DataFrame(predictions.detach().cpu().numpy(), columns=['predictions']).to_csv('submission.csv')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB-ezFJER7vZ"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 5. Upload your final predictions (the file* `submission.csv` *) to **Homework 2 - Code** on **NextIlearn***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}